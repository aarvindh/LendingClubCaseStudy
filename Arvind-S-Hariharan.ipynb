{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data set\n",
    "loan_dataSet = pd.read_csv(\"D:\\loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the top 5 rows of the data to begin the analysis\n",
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows in dataset based on id column\n",
    "\n",
    "print(loan_dataSet.duplicated(subset=None, keep='first').count())\n",
    "duplicates=loan_dataSet[loan_dataSet.duplicated(['id'])]\n",
    "duplicates\n",
    "\n",
    "# There are no duplicate rows in loan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the null values in all the columns in the given data set\n",
    "loan_dataSet.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is observed that there are a lot of columns with all null values. Hence we can remove/drop those null valued columns as they are not useful for our further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_dataSet.dropna(axis = 1, how = 'all', inplace = True)\n",
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also to be noted that there are several columns which are single valued and they would  not be helpful futher to our analysis. Hence removing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.drop(['pymnt_plan', \"initial_list_status\",'collections_12_mths_ex_med','policy_code','acc_now_delinq', 'application_type', 'pub_rec_bankruptcies', 'tax_liens', 'delinq_amnt'], axis = 1, inplace = True)\n",
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have 48 columns out of which some correspond to the post approval of loan\n",
    "- We need to analyze user details and the factors which plays a major role in the loan application defaulting\n",
    "- We can go ahead and remove the columns that are not useful to our analysis from the data set.\n",
    "- There are some clmns such as \"id\", \"member_id\", \"url\", \"title\", \"emp_title\", \"zip_code\", \"last_credit_pull_d\", \"addr_state\". \n",
    "- The above features or columns is not useful to the loan defaulting due to incorrect or not related information. Hence removing them. \n",
    "- \"desc\" has description (text data) which is not useful. Hence removing the column.\n",
    "- \"out_prncp_inv\" , \"total_pymnt_inv \" are also not useful for analysis. Hence removing them. \n",
    "- As we have \"funded_amnt_inv\" , we can remove the funded_amnt column as well as it is not needed\n",
    "\n",
    "### Columns post approval that can be removed\n",
    "- delinq_2yrs\n",
    "- revol_bal\n",
    "- out_prncp\n",
    "- total_pymnt\n",
    "- total_rec_prncp\n",
    "- total_rec_int\n",
    "- total_rec_late_fee\n",
    "- recoveries\n",
    "- collection_recovery_fee\n",
    "- last_pymnt_d\n",
    "- last_pymnt_amnt\n",
    "- next_pymnt_d\n",
    "- chargeoff_within_12_mths\n",
    "- mths_since_last_delinq\n",
    "- mths_since_last_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.drop([\"id\", \"member_id\", \"url\", \"title\", \"emp_title\", \"zip_code\", \"last_credit_pull_d\", \"addr_state\",\"desc\",\"out_prncp_inv\",\"total_pymnt_inv\",\"funded_amnt\", \"delinq_2yrs\", \"revol_bal\", \"out_prncp\", \"total_pymnt\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\", \"next_pymnt_d\" , \"chargeoff_within_12_mths\", \"mths_since_last_delinq\", \"mths_since_last_record\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Actual Columns list which is useful now for the next set of analysis\n",
    "loan_dataSet.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main aim of this analysis is to check which user is likely to default based on the fully paid status or if the loan is charged off. Hence there is no use of having current values in the loan_status column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing the rows with loan status as current\n",
    "loan_dataSet = loan_dataSet[loan_dataSet.loan_status != \"Current\"]\n",
    "### Check the unique values after removing the current loans\n",
    "loan_dataSet.loan_status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step is to check for missing values if any in the final list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loan_dataSet.isna().sum()/len(loan_dataSet.index))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing values\n",
    " - columns with missing values are \"emp_length\", \"revol_util\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Check the datatype of the columns \"emp_length\" and \"revol_util\"\n",
    "loan_dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Check the Mode value of emp_length column\n",
    "\n",
    "print(\"Mode value of emp)length coulmn : \" + loan_dataSet.emp_length.mode()[0])\n",
    "loan_dataSet.emp_length.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mode value has far higher frequency than that of the next most frequent value. \n",
    "- Lets format employment length column to have only numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.emp_length.fillna(loan_dataSet.emp_length.mode()[0], inplace = True)\n",
    "loan_dataSet.emp_length.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.dropna(axis = 0, subset = ['revol_util'] , inplace = True)\n",
    "loan_dataSet.revol_util.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization/Correction of data\n",
    "- \"revol_util\" column although described as an object column, it has continous values. \n",
    "- So we need to standardize the data in this column\n",
    "- \"int_rate\" is one such column.\n",
    "- \"emp_length\" --> { (< 1 year) is assumed as 0 and 10+ years is assumed as 10 }\n",
    "- The datatype of \"term\" is defined as an int, and there onl two values in the whole column and hence it can be considered as categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.revol_util = pd.to_numeric(loan_dataSet.revol_util.apply(lambda x : x.split('%')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.int_rate = pd.to_numeric(loan_dataSet.int_rate.apply(lambda x : x.split('%')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.emp_length = pd.to_numeric(loan_dataSet.emp_length.apply(lambda x: 0 if \"<\" in x else (x.split('+')[0] if \"+\" in x else x.split()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Outliers in \"annual_inc\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_dataSet['annual_inc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly indicating the presence of outliers.\n",
    "- Remove the outliers initially\n",
    "- Check the quantile information\n",
    "- The values after 95 percentile seems to be disconnected from the general distribution and also there is huge increase in the value for small quantile variation.\n",
    "- Hence, considering threshold for removing outliers as 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_info = loan_dataSet.annual_inc.quantile([0.5, 0.75,0.90, 0.95, 0.97,0.98, 0.99])\n",
    "quantile_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_95_annual_inc = loan_dataSet['annual_inc'].quantile(0.95)\n",
    "loan_dataSet = loan_dataSet[loan_dataSet.annual_inc <= per_95_annual_inc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_dataSet.annual_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now \"annual_inc\" data looks good and proceeding with next set of  numerical column values\n",
    "- Analyzing other numerical variables which could possibly have outliers such as the following-\n",
    "- dti\n",
    "- loan_amnt\n",
    "- funded_amnt_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_dataSet.dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_dataSet.loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.loan_amnt.quantile([0.75,0.90,0.95,0.97,0.975, 0.98, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_dataSet.funded_amnt_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.funded_amnt_inv.quantile([0.5,0.75,0.90,0.95,0.97,0.975, 0.98,0.985, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The distribution is continous and there is no need to remove outliers / extreme values for these above columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Categorical Data Sets\n",
    "### We already have grade column, extracting only subgrade (int level value) from the sub_grade variable\n",
    "- We are analyzing and visualizing only the defaulter data. So subsetting the data while plotting only for 'Charged Off' loan_status for below plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'loan_status', data = loan_dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.sub_grade = pd.to_numeric(loan_dataSet.sub_grade.apply(lambda x : x[-1]))\n",
    "loan_dataSet.sub_grade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,8))\n",
    "sns.set_palette('husl')\n",
    "sns.countplot(x = 'grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] , hue = 'sub_grade',data = loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'grade', data = loan_dataSet[loan_dataSet.loan_status == 'Charged Off'], order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps is to analyze home_ownership column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking unique values for home_ownership\n",
    "loan_dataSet['home_ownership'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are only 3 records with 'NONE' value in the data. So replacing the value with 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing 'NONE' with 'OTHERS'\n",
    "loan_dataSet['home_ownership'].replace(to_replace = ['NONE'],value='OTHER',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking unique values for home_ownership again\n",
    "loan_dataSet['home_ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "ax.set(yscale = 'log')\n",
    "sns.countplot(x='home_ownership', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyzing the purpose of loan taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.set(xscale = 'log')\n",
    "sns.countplot(y ='purpose', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating bins for some numerical variable to make them categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create additional bins for int_rate,open_acc,revol_util,total_acc based on ranges\n",
    "loan_dataSet['int_rate_groups'] = pd.cut(loan_dataSet['int_rate'], bins=5,precision =0,labels=['5%-9%','9%-13%','13%-17%','17%-21%','21%-24%'])\n",
    "loan_dataSet['open_acc_groups'] = pd.cut(loan_dataSet['open_acc'],bins = 5,precision =0,labels=['2-10','10-19','19-27','27-36','36-44'])\n",
    "loan_dataSet['revol_util_groups'] = pd.cut(loan_dataSet['revol_util'], bins=5,precision =0,labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "loan_dataSet['total_acc_groups'] = pd.cut(loan_dataSet['total_acc'], bins=5,precision =0,labels=['2-20','20-37','37-55','55-74','74-90'])\n",
    "loan_dataSet['annual_inc_groups'] = pd.cut(loan_dataSet['annual_inc'], bins=5,precision =0,labels =['3k-31k','31k-58k','58k-85k','85k-112k','112k-140k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing new bins created\n",
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing interest rate w.r.t the interest rate bins created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,7))\n",
    "plt.subplot(221)\n",
    "sns.countplot(x='int_rate_groups', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])\n",
    "plt.xlabel('Interest Rate')\n",
    "plt.subplot(222)\n",
    "sns.countplot(x='emp_length', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly analyzing open_acc,revol_util,total_acc,annual_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='open_acc_groups', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='revol_util_groups', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='total_acc_groups', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,4))\n",
    "sns.countplot(x='annual_inc_groups', data=loan_dataSet[loan_dataSet.loan_status == 'Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y='term', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='verification_status', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (8,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='inq_last_6mths', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (7,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='pub_rec', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Lets Analyze the loan issued by month and year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting month and year\n",
    "df_month_year = loan_dataSet['issue_d'].str.partition(\"-\", True)     \n",
    "loan_dataSet['issue_month']=df_month_year[0]                       \n",
    "loan_dataSet['issue_year']='20' + df_month_year[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "sns.countplot(x='issue_month', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])\n",
    "plt.subplot(222)\n",
    "sns.countplot(x='issue_year', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum number of loan defaults occured when the it was sanctioned/issued in the month of Dec. Comparison with other years are also shown \n",
    "\n",
    "### Analyzing installment,dti, loan_amnt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dataSet['installment_groups'] = pd.cut(loan_dataSet['installment'], bins=10,precision =0,labels=['14-145','145-274','274-403','403-531','531-660','660-789','789-918','918-1047','1047-1176','1176-1305'])\n",
    "loan_dataSet['funded_amnt_inv_group'] = pd.cut(loan_dataSet['funded_amnt_inv'], bins=7,labels=['0-5k','5k-10k','10k-15k','15k-20k','20k-25k','25k-30k','30k-35k'])\n",
    "loan_dataSet['loan_amnt_groups'] = pd.cut(loan_dataSet['loan_amnt'], bins=7,precision =0,labels=['0-5k','5k-10k','10k-15k','15k-20k','20k-25k','25k-30k','30k-35k'])\n",
    "loan_dataSet['dti_groups'] = pd.cut(loan_dataSet['dti'], bins=5,precision =0,labels=['0-6','6-12','12-18','18-24','24-30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='funded_amnt_inv_group', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='loan_amnt_groups', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='dti_groups', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='installment_groups', data=loan_dataSet[loan_dataSet['loan_status']=='Charged Off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following are the inferences/observation that we can make based on the plots that we have developed assessing alll the relevant columns\n",
    "\n",
    "### The last months of an year indicated the high possibility of defaulting.\n",
    "\n",
    "### The above analysis with respect to the charged off loans for each variable suggests the following. There is a more probability of defaulting when : \n",
    "\n",
    "- Applicants having house_ownership as 'RENT'\n",
    "- Applicants who use the loan to clear other debts\n",
    "- Applicants who receive interest at the rate of 13-17%\n",
    "- Applicants who have an income of range 31201 - 58402\n",
    "- Applicants who have 20-37 open_acc\n",
    "- Applicants with employement length of 10\n",
    "- When funded amount by investor is between 5000-10000\n",
    "- Loan amount is between 5429 - 10357\n",
    "- Dti is between 12-18\n",
    "- When monthly installments are between 145-274\n",
    "- Term of 36 months\n",
    "- When the loan status is Not verified\n",
    "- When the purpose is 'debt_consolidation'\n",
    "- Grade is 'B'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets see what all observations can we get based on correlation matrix -w.r.t Quantitative Variables\n",
    "### Bivariate Analysis - Correlation Matrix-Quantitative Variables\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loandata_correlation = loan_dataSet.corr()\n",
    "sns.clustermap(loandata_correlation,annot=True,figsize=(12, 8),cmap=\"BrBG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the above correlation graph it seems that Loan amount, investor amount, funding amount are strongly correlated.\n",
    "### Annual income with DTI(Debt-to-income ratio) is negatively correalted.\n",
    "### Debt income ratio is the percentage of a consumer's monthly gross income that goes toward paying debts. \n",
    "### When annual income is low DTI is high & vice versa.\n",
    "### Positive correlation between annual income and employment years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps we can Analyse annual income with other columns as well using Bar plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Annual income vs loan purpose. We can plot a Bar plot in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='annual_inc', y='purpose', hue ='loan_status',palette=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicants with higher salary mostly applied loans for \"home_improvment\", \"house\", \"renewable_energy\" and \"small_businesses\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Annual income vs home ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='home_ownership', y='annual_inc', hue ='loan_status',palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Income vs Loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"annual_inc_groups\", y = \"loan_amnt\", hue = 'loan_status', data = loan_dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Across all the income groups, the loan_amount is higher for people who defaulted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Annual income vs int_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='int_rate_groups', y='annual_inc', hue ='loan_status',palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can Analyse loan_amount with other columns as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Loan Amount vs Interest Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='loan_amnt_groups', y='int_rate', hue ='loan_status',palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Loan vs Loan purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='loan_amnt', y='purpose', hue ='loan_status',palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Loan vs House Ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='loan_amnt', y='home_ownership', hue ='loan_status',palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Loan amount vs month issued and year issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(221)\n",
    "sns.lineplot(data =loan_dataSet,y='loan_amnt', x='issue_month', hue ='loan_status',palette=\"husl\")\n",
    "plt.subplot(222)\n",
    "sns.lineplot(data =loan_dataSet,y='loan_amnt', x='issue_year', hue ='loan_status',palette=\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Loan amount vs Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_dataSet,x='loan_amnt', y='grade', hue ='loan_status',palette=\"husl\", order=['A','B','C','D','E','F','G'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan_amount vs emp_length and verification_status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(221)\n",
    "sns.barplot(data =loan_dataSet,y='loan_amnt', x='emp_length', hue ='loan_status',palette=\"husl\")\n",
    "plt.subplot(222)\n",
    "sns.barplot(data =loan_dataSet,y='loan_amnt', x='verification_status', hue ='loan_status',palette=\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employees with longer working history got the loan approved for a higher amount. \n",
    "- Looking at the verification status data, verified loan applications tend to have higher loan amount. Which might indicate that the firms are first verifying the loans with higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grade vs interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(data =loan_dataSet,x='int_rate', y='grade', hue ='loan_status',palette=\"husl\", order=['A','B','C','D','E','F','G'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize = (15,6))\n",
    "plt.tight_layout()\n",
    "sns.catplot(data =loan_dataSet,y ='int_rate', x ='loan_amnt_groups', hue ='loan_status',palette=\"husl\",kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The interest rateis very high for the charged off loans than that of fully paid ones based on the derivation from above graph \n",
    "- This can be a one of the main reasons for loan defaulting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'term', y = 'loan_amnt', data = loan_dataSet,hue = 'loan_status', kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicants who applied and defaulted have no significant difference in loan_amounts.\n",
    "- Which means that applicants applying for long term has applied for more loan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Inferences/Observations based on the various retionships between loan_amount and other driving factors for defaulting or a person becoming a loan defaulter\n",
    "\n",
    "\n",
    "- Users who take loan for 'home improvement' have income of 60k -70k\n",
    "- Users whose home ownership type is of 'MORTGAGE, have income of 60-70k\n",
    "- Users who receive interest at the rate of 21%-24%, have an income of 70k-80k\n",
    "- Users who have taken a loan in the range 30k - 35k and are charged interest rate of 15%-17.5%\n",
    "- Users who have taken a loan for small business, the loan amount is greater than 14k\n",
    "- Users whose home ownership is 'MORTGAGE, have loan of 14-16k\n",
    "- When grade is F then loan amount is between 15k-20k\n",
    "- When employment length is 10yrs, loan amount is 12k-14k \n",
    "- When the loan is verified and loan amount is above 16k\n",
    "- For grade G, the interest rate is above 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
